%!TEX root = ../main.tex

\newpage
\section*{Tables and Figures}

% Tables

  \begin{table}[H]
    \centering
    \small
    \begin{tabular}{|c|c|c|c|}
      \hline
      \textbf{Workflow step} & \textbf{Module/Condition} & \textbf{Tool/Parameter} & \textbf{References/Value} \\
      \hline
      \multirow{7}{*}{Denoising and Clustering} & \multirow{5}{*}{Denoise and Cluster} & Closed reference & \cite{rognesVSEARCHVersatileOpen2016,bolyenReproducibleInteractiveScalable2019} \\
                                                &  & Open reference & \cite{rognesVSEARCHVersatileOpen2016,bolyenReproducibleInteractiveScalable2019} \\
                                                &  & De novo & \cite{rognesVSEARCHVersatileOpen2016,bolyenReproducibleInteractiveScalable2019} \\
                                                &  & \rowcolor{lightgray} Dada2 & \cite{Callahan2016} \\
                                                &  & Deblur & \cite{Amir2017,bolyenReproducibleInteractiveScalable2019} \\
                                                \cline{2-4}
                                                & \multirow{2}{*}{Chimera checking} & Uchime-denovo & \cite{rognesVSEARCHVersatileOpen2016,bolyenReproducibleInteractiveScalable2019} \\
                                                & & \rowcolor{lightgray} Remove bimera & \cite{Callahan2016} \\
                                                \hline
      \multirow{5}{*}{Taxonomy assignment} &  \multirow{2}{*}{Query tool} & Blast & \cite{camachoBLASTArchitectureApplications2009,bokulichOptimizingTaxonomicClassification2018} \\
                                           &  & \rowcolor{lightgray} Naive bayes classifier & \cite{bokulichOptimizingTaxonomicClassification2018} \\
                                           \cline{2-4}
                                           & \multirow{3}{*}{Database} & \rowcolor{lightgray} Greengenes 13\_8 & \cite{DeSantis2006} \\
                                           & & SILVA 138 & \cite{Quast2012} \\
                                           & & NCBI RefSeq (Oct 2021) & \cite{Sayers2009} \\
      \hline
      \multirow{6}{*}{OTU processing} & \multirow{3}{*}{Filter(off)} & Prevalence threshold      & 2 / n\_samples \\
                                      & & Abundance threshold       & 0.001          \\
                                      & & Observation sum threshold & 10             \\ \cline{2-4}
                                      & \multirow{3}{*}{Filter(on)}  & \rowcolor{lightgray} Prevalence threshold      & 0.05           \\
                                      & & \rowcolor{lightgray} Abundance threshold       & 0.01           \\
                                      & & \rowcolor{lightgray} Observation sum threshold & 100            \\
      \hline
      \multirow{12}{*}{Network Inference} & \multirow{2}{*}{Bootstrapping}& fastspar\_bootstraps v1.0 & \cite{Watts2018} \\
                                          & & fastspar\_pvalues v1.0 & \cite{Watts2018} \\
                                          \cline{2-4}
                                          & \multirow{6}{*}{Direct association} & \ac{spieceasi} v1.1.2 & \cite{Kurtz2015} \\
                                          & & FlashWeave.jl v0.18.1 & \cite{tackmannRapidInferenceDirect2019} \\
                                          & & \ac{cozine} v1.0 & \cite{haCompositionalZeroinflatedNetwork2020a} \\
                                          & & \ac{harmonies} v1.0 & \cite{jiangHARMONIESHybridApproach2020} \\
                                          & & \ac{spring} v1.0.4 & \cite{yoonMicrobialNetworksSPRING2019} \\
                                          & & \ac{mldm} v1.1 & \cite{Yang2017} \\
                                          \cline{2-4}
                                          & \multirow{2}{*}{Correlation-based} & FastSpar (\ac{sparcc}) v1.0 & \cite{Watts2018} \\
                                          & & Pearson & - \\
                                          & & Spearman & - \\
                                          & & propr v2.1.2 & \cite{quinnProprRpackageIdentifying2017} \\ \cline{2-4}
                                          & \multirow{2}{*}{Consensus algorithm} & \rowcolor{lightgray} scaled-sum & 0.333 \\
                                          & & simple voting & 1.000 \\
      \hline
    \end{tabular}
    \caption{
      \textbf{Tools used in the \ac{micone} pipeline}.
      The tools highlighted in gray are the defaults for the pipeline and are recommended based on the benchmarks with the mock and synthetic datasets.
      The consensus algorithm in the \ac{ni} step incorporates all the modules (bootstrapping, direct association and correlation-based) in that step to generate the consensus network.
    }
    \label{tab:micone_tools}
  \end{table}

% Figures

  \FloatBarrier
  \newpage

  \FloatBarrier
  \newpage
  % \begin{figure}[H]
  %   \centering
  %   \includegraphics[width=0.74\linewidth]{figure1.pdf}
  % \end{figure}
  \begin{figure}[H]
    \centering
    \caption{
      \textbf{The workflow of the \ac{micone} pipeline}.
      The steps of the workflow can be broken down into five major groups: \textbf{(SP)} \textbf{S}equence \textbf{P}rocessig, \textbf{(DC)} \textbf{D}enoising and \textbf{C}lustering, \textbf{(TA)} \textbf{T}axonomy \textbf{A}ssignment, \textbf{(OP)} \textbf{O}TU and ESV \textbf{P}rocessing, and \textbf{(NI)} \textbf{N}etwork \textbf{I}nference.
      Each step incorporates several processes, each of which in turn have several alternate algorithms for the same task (indicated by the text to the right of the blue boxes).
      The text along the arrows describes the data that is being passed from one step to another.
      The final output of the pipeline is the consensus network generated from the inferred co-occurrence networks.
      For details on each process and the data outputs, see Methods.
    }
    \label{fig:figure1}
  \end{figure}



  \FloatBarrier
  \newpage
  % \begin{figure}[H]
  %   \centering
  %   \includegraphics[width=\textwidth]{figure2.pdf}
  % \end{figure}
  \begin{figure}[H]
    \centering
    \caption{
      \textbf{The representative sequences generated by the different denoising/clustering methods are very similar but differ in the sequences that are lower in abundance.}
      \textbf{(A)} The average weighted UniFrac distance between the representative sequences shows that the representative sequences and their compositions are fairly identical between the methods (with the exception of Deblur (DB)).
      \textbf{(B)} The relatively larger average unweighted UniFrac distance indicates that methods differ in their identification of sequences that are lower in abundance.
      The number of \ac{otu}s or \ac{esv}s generated by the respective methods are provided in the parenthesis next to the names.
      The data used for the analysis in \textbf{(A, B)} were all the samples (healthy and autistic) from the fecal microbiome transplant dataset.
      \textbf{(C, D)} The distributions of the average weighted and unweighted UniFrac distance between the expected sequence profile and the predicted sequence profile in the mock datasets.
      The distributions of the average weighted UniFrac distance show that de novo (DN) and open reference (OR) were the best-performing methods in most of the datasets, while they are worst performing methods under the unweighted UniFrac metric.
      The good performance of dada2 (D2) under both distance metrics combined with its approach of identifying \ac{esv}s using de novo methods, prompts us to propose it as the default method for the DC step.
      The data used for the analysis in \textbf{(C, D)} were the mock datasets from mockrobiota~\cite{Bokulich2016}.
    }
    \label{fig:figure2}
  \end{figure}


  \FloatBarrier
  \newpage
  % \begin{figure}[H]
  %   \centering
  %   \includegraphics[width=\textwidth]{figure3.pdf}
  % \end{figure}
  \begin{figure}[H]
    \centering
    \caption{
      \textbf{Taxonomic reference databases vary widely in terms of their taxonomy assignments beyond the Order level.}
      \textbf{(A)} The assignments of the top 50 representative sequences to their respective taxonomies using the three different reference databases.
      This result illustrates how the same sequences are assigned to different Genus under different databases.
      A significant portion of the representative sequences are assigned to an ``unknown'' Genus in two of three databases (\ac{gg} and \ac{ncbi}).
      \textbf{(B)} The number of representative sequences assigned to the same taxonomic label when using different reference databases, shown for the top 100 sequences.
      The number of mismatches are fewer at higher taxonomic levels, but, even at the Order level there exists greater than 51\% of mismatches, demonstrating the poor agreement in taxonomic labels assigned by the different databases.
      The data used for the analysis in \textbf{(A, B)} were all the samples (healthy and autistic) from the fecal microbiome transplant dataset.
      \textbf{(C)} The Bray-Curtis dissimilarity between the expected taxonomy profile and calculated taxonomy profile in the mock datasets shows that there is no singular best choice of database for every dataset, as all the databases have similar performance.
      However, we still recommend the \ac{gg} database and the Naive Bayes classifier as the defaults for the \ac{micone} pipeline.
      Due to the popularity of the \ac{gg} database, comparison against existing networks in literature will be easier since many published datasets make use of this database in their analyses.
      The datasets used for the analysis in \textbf{(C)} were the mock datasets from mockrobiota.
    }
    \label{fig:figure3}
  \end{figure}


  \FloatBarrier
  \newpage
  % \begin{figure}[H]
  %   \centering
  %   \includegraphics[width=\textwidth]{figure4.pdf}
  % \end{figure}
  \begin{figure}[H]
    \centering
    \caption{
      \textbf{Networks generated using different network inference methods show notable differences both in terms of edge-density and connectivity}.
      \textbf{(A)} The nine different networks (excluding \ac{mldm}) generated by the different network inference methods are very dissimilar.
      The green links are positive associations and the orange links represent negative associations.
      A threshold of 0.3 was set for the correlation-based methods (\ac{sparcc}, Propr, Spearman and Pearson) and a threshold of 0.01 was set for the other direct association methods.
      The correlation-based methods in general produce graph with higher edge-densities.
      \textbf{(B)} The node overlap Upset plot indicates that all the networks have a large proportion of common nodes involved in connections (33 out of 68).
      Whereas, \textbf{(C)} the edge overlap Upset plot shows that a very small fraction of these connections are actually shared (8 out of 202).
      The data used in this analysis were the healthy stool samples from the fecal microbiome transplant dataset.
      \ac{mldm} is not shown in the comparisons because the algorithm failed to converge for most of the network combinations.
    }
    \label{fig:figure4}
  \end{figure}


  % TODO: Move caption to Figure S6
  % Give reason for using those 4 individual methods
  \FloatBarrier
  \newpage
  % \begin{figure}[H]
  %   \centering
  %   \includegraphics[width=1.0\linewidth]{figure5.pdf}
  % \end{figure}
  \begin{figure}[H]
    \centering
    \caption{
      \textbf{The precision and sensitivity of the inferred networks on the NorTA synthetic interaction data.}
      The ``I'' prefix indicates the individual network inference methods and the ``X'' prefix denotes the consensus based methods that are a part of \ac{micone}.
      The different consensus based methods used are: pvalue merging (PM), scaled-sum (SS) and simple voting (SV) method.
      Pearson and Spearman methods are not used in the calculation of the consensus.
      Among all the independent network inference methods, \ac{spieceasi} has the best average precision (0.944), but the overall best precision was consistently obtained by the scaled-sum method (0.956, 0.985 and 1.000).
      The simple voting method when using presence of edges in all inferred networks as a requirement (parameter value 1.000), also outperforms \ac{spieceasi} on average precision (0.969).
      Although \ac{spieceasi} has a higher performance on sensitivity, if the goal of network inference is to obtain the list of associations that have a high probability of existing in the real microbial community, then the consensus methods perform better.
      Therefore, we recommend the scaled-sum consensus method as the default tool for network inference.
    }
    \label{fig:figure5}
  \end{figure}


  \FloatBarrier
  \newpage
  % TODO: Add equations for the linear model to the left of the pie chart
  % \begin{figure}[H]
  %   \centering
  %   \includegraphics[width=\textwidth]{figure6.pdf}
  % \end{figure}
  \begin{figure}[H]
    \centering
      \caption{
      \textbf{The choice of reference database contributes to the most variance in the networks}.
      \textbf{(A)} The percentage of variance in the networks contributed by the DC, CC (chimera checking), TA and OP steps of the pipeline (right) and the linear model used to calculate the variance (left), see the Methods section for details.
      The data used for the analysis were the healthy stool samples from the fecal microbiome transplant dataset~\cite{Kang2017}.
      The taxonomy database contributes most to the variance between the networks (65.4\%) followed by the filtering of the counts matrix (26.8\%) in the OP step.
      The variation due to the DC and CC steps are comparatively not as significant.
      The fraction labeled as the residual is an artifact that arises when multiple steps are changed at the same time, however, this can be ignored as this fraction is negligible.
      \textbf{(B)} All combinations of inferred networks are shown as points on a PCA plot.
      Each point on the PCA plot represents a network inferred using different combinations of tools and parameters that are available in the \ac{micone} pipeline.
      The color of the points corresponds to the reference taxonomy database used to reconstruct those networks (left), and the network inference algorithm used to infer the networks (right).
      The points on the PCA plot can be grouped based on the TA step, but at the NI step only some methods create high variability in the inferred networks.
    }
    \label{fig:figure6}
  \end{figure}


  \FloatBarrier
  \newpage
  % TODO: Verify the validity of Figure 7A and 7B again
  % Are they both using consensus?
  % \begin{figure}[H]
  %   \centering
  %   \includegraphics[width=1.0\linewidth]{figure7.pdf}
  % \end{figure}
  \begin{figure}[H]
    \centering
    \caption{
      \textbf{The consensus algorithm drastically reduces variability in the networks due to upstream data processing methods and increases robustness of inferred networks}
      \textbf{(A)} The network constructed using the default pipeline parameters (DC=\ac{dada2}, CC=remove bimera, TA=\ac{gg}, OP=Filter(on), NI=scaled-sum consensus) is compared with networks generated when one of the steps use a different tool.
      The common connections (common with the default network) are in black, connections unique to the network are colored purple and connections in the default network, but not present in the current network are gray.
      Changing the NI, TA and OP steps leads to the creation of the most number of new nodes and edges.
      \textbf{(B)} The boxplot showing the L1 distance between the default network and the networks generated by changing one step of the default pipeline.
      The high value of L1 distances for the network inference step as compared to the other steps demonstrates how the consensus method is able to reduce the variability in the networks in the other steps of the pipeline.
      This also shows that even though many new nodes were added in (A) when the TA and OP steps were changed, the L1 distances remain fairly small.
      \textbf{(C)} The networks generated for the control (left) and autistic (right) samples in the fecal microbiome transplant dataset.
      These networks were generated using the default tools and parameters recommended by the \ac{micone} pipeline.
      The data used in this analysis were the healthy stool samples from the fecal microbiome transplant dataset.
    }
    \label{fig:figure7}
  \end{figure}


