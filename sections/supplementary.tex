%!TEX root = ../main.tex

\newpage
\section*{Supplementary}

  \renewcommand{\thefigure}{S\arabic{figure}}
  \setcounter{figure}{0}

  \renewcommand{\thetable}{S\arabic{table}}
  \setcounter{table}{0}

  \input{sections/supplementary_table.tex}

  \subsection{Configuration used for MiCoNE runs}

  \subsection{Generation of sequence data}

  \subsubsection{Mock sequence data}
  Mock 4: A mock community composed of 21 bacterial strains represented in equal abundances in two replicate samples, and the same strains represented in uneven abundances in two replicate samples. These are the same community members present in mock-3 and mock-5, which consists of the same mock community samples analyzed on separate Illumina sequencing runs. This was generated by Dr. Dirk Gevers at Broad Institute in 2012. Previously called dataset-3 in [Bokulich et al. 2013](https://dx.doi.org/10.1038/nmeth.2276) and dataset B4 in [Bokulich et al. 2015](https://dx.doi.org/10.7287/peerj.preprints.934v2).

  Mock 12: Composed of 27 bacterial strains amplified with 515f/806r primers. Intended to include more closely related taxa than the other mock communities, the members of which were chosen in part for their well-separated 16S rRNA gene sequences. These strains are all distinguishable over the sequenced region of the 16S rRNA gene, but some pairs of strains differ by as little as one nucleotide. Generated by Benjamin Callahan at Stanford University in 2015. Known as "Extreme" dataset in the original publication, doi:10.1038/nmeth.3869.

  Mock 16: Mock community generated by Melanie Schirmer at University of Glasgow in 2015. Composed of even amounts of purified genomic DNA from 49 bacteria and 10 archaea. Known as dataset 35 in the original publication, doi:10.1093/nar/gku1341.

  \subsubsection{Synthetic sequence data}
  - We first create a sequence pool for various samples. This will have mutated (2\% mutation rate) reference sequences at abundances that are close to real abundances
  - We then use `art_illumina` with 1x fold_coverage to generate fastq read files for each sample.

    We created reference sequences that are 1/10th or 1/100th such that we have repeating sequences. Eg. If we have 3500 total reads, and 90\% are from same taxonomy, we have 32 or 315 reads of this sequence then we can fix `-f` as 3500/multiplier. To get multiplier we  could look at low abundant sequence and how much do we need to have atleast one of these sequences. OR should I just have fold coverage of 1x and 3500 references? Make 2\% of the positions in each sequence randomly mutate to create nucleotide diversity [source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5967554/)

  \subsection{Generation of synthetic interaction data}
  Figures describing the original OTU tables or the interactions used to generate the community. Also include the seed and scripts for reproducing the networks.

  \subsection{Consensus and p-value}

  % FIXME: Should this section be rewritten? Ask Daniel
  \subsubsection*{p-value merging}
  Fisher~\cite{fisher_224a_1948} proposed that for $k$ independent p-values, each generated by $k$ different methods and denoted by $P_i$, the statistic $\Psi$:
  \begin{equation*}
    \begin{aligned}
        \Psi &= \sum_{i=1}^k -2 \log \left( P_i \right) \\
        \Psi &\sim \chi^2_{2k}
    \end{aligned}
  \end{equation*}

  Brown~\cite{brown_400_1975} extended Fisher's method to dependent p-values by using a re-scaled $\chi^2$ distribution:
  \begin{equation*}
    \Psi \sim c \chi^2_{2f}
  \end{equation*}
  where, $f$ is the degrees of freedom and $c$ is the scale factor and are given by:
  \begin{equation*}
    f = \frac{\mathrm{E}[\Psi]^2}{\mathrm{Var}[\Psi]} ~~~\text{and}~~~ c = \frac{\mathrm{Var}[\Psi]}{2\mathrm{E}[\Psi]} = \frac{k}{f}
  \end{equation*}

  Furthermore, Brown showed that $\mathrm{E}[\Psi]$ and $\mathrm{Var}[\Psi]$ can be calculated directly via a numerical integration:
  \begin{equation*}
    \mathrm{E}[\Psi] = 2k ~~~\text{and}~~~ \mathrm{Var}[\Psi] = 4k + 2\sum_{i<j} \mathrm{Cov}\left( -2\log(P_i), -2\log(P_j) \right)
  \end{equation*}

  Kost and McDermott~\cite{kost_combining_2002} further fit a third-order polynomial to approximate the covariance
  \begin{equation}
    \mathrm{Cov}\left( -2\log(P_i), -2\log(P_j) \right) \approx 3.263 \rho_{ij} + 0.710 \rho_{ij}^2 + 0.027 \rho_{ij}^3
    \label{eqn:covariance-pvalues}
  \end{equation}
  where, $\rho_{ij}$ is the correlation between method $i$ and method $j$

  The final combined p-value~\cite{Poole_Gibbs_Shmulevich_Bernard_Knijnenburg_2016} is then given by:
  \begin{equation}
    \begin{aligned}
        & P_{combined} = 1.0 - \Phi_{2f}\left( \psi / c \right) \\
        \text{where},~ &\psi = -2 \sum_{i=1}^k \log(P_i) ~~~\text{and}~~~ \Phi_{2f} = \mathrm{CDF}\left( \chi^2_{2f} \right)
    \end{aligned}
    \label{eqn:pvalue-combined}
  \end{equation}

  The p-value merging method in \ac{micone} (refer Documentation) uses Equation~\ref{eqn:covariance-pvalues} to estimate the covariance of the pvalues and Equation~\ref{eqn:pvalue-combined} to merge the p-values (obtained from bootstrapping) from the different correlation methods.
  % FIXME: Not sure what our stance on this is?
  Note that we do not use Pearson and Spearman methods in the p-value merging step and these algorithms are only used for demonstration and comparison.
  The combined p-values are used to threshold for significance during the consensus network step.

  \begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figureS1.pdf}
  \caption{
    \textbf{Comparison of various denoising and clustering algorithms used in the pipeline}.
    (A, B) Correlation of the abundances of the taxa that are in common between the count matrices created by two different methods.
    (A) The worst correlation (least similar methods) is between open-reference and dada2.
    (B) The best correlation (most similar methods) is between open-reference and denovo.
    (C) A heatmap showing the $\mathrm{R}^2$ of all pairwise comparisons of the methods.
  }
  \label{fig:figureS1}
\end{figure}

  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figureS2.pdf}
    \caption{
      \textbf{Heatmaps showing the weighted and unweighted unifrac distances for the hard palate dataset analysis}.
      (A) weighted unifrac distances and (B) unweighted unifrac distances between the representative sequences generated by different denoising and clustering algorithms.
      These results are in agreement with the stool microbiome dataset.
    }
    \label{fig:figureS2}
  \end{figure}

  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figureS3.pdf}
    \caption{
      \textbf{The distributions of the average weighted UniFrac distance between the expected sequence profile and the calculated sequence profile in the synthetic datasets}.
      We observe no significant difference between the various methods on the synthetic datasets used for this study.
    }
    \label{fig:figureS3}
  \end{figure}

%   \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.9\linewidth]{pdf/all_denoise_reg.pdf}
%     \caption*{All pairwise correlations comparing the similarity between different denoising and clustering methods}
%     \label{fig:figureS4}
%   \end{figure}

  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figureS4.pdf}
    \caption{
      \textbf{(A)} Taxonomy composition of the 20 most abundant genera predicted for the stool microbiome dataset generated using different taxonomy references databases: Greengenes, SILVA and NCBI.
      The legend shows the common and the unique genera among the taxonomy assignments.
  }
    \label{fig:figureS4}
  \end{figure}

  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figureS5.pdf}
    \caption{
      The bray-curtis dissmilarity between the expected taxonomic composition and generated taxonomic composiion for the synthetic datasets.
  }
  \label{fig:figureS5}
  \end{figure}

%   \begin{figure}[h]
%     \centering
%     \includegraphics[width=\linewidth]{figureS6.pdf}
%     \caption{
%       Calculation of presence threshold that is applied on the OTU table in the OTU processing (OP) step of the pipeline.
%       This presence threhold $p_t$ is dependent on the number of samples in the dataset and the required correlation stength threshold.
%   }
%     \label{fig:figureS6}
%   \end{figure}

  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figureS8.pdf}
    \caption{
      The similarity between the networks generated using the different network inference algorithms for stool dataset (A) and the hard palate dataset (B).
      The similarity between the various methods was found to vary with the dataset used.
  }
    \label{fig:figureS8}
  \end{figure}

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{pdf/denoise_network.pdf}
    \caption{A network showing union (A) and intersection (B) of networks generated using different denoising and clustering tools on the Stool dataset.}
    \label{fig:figureS5}
  \end{figure}
