%!TEX root = ../main.tex

\newpage
\section*{Supplementary}

  \renewcommand{\thefigure}{S\arabic{figure}}
  \setcounter{figure}{0}

  \renewcommand{\thetable}{S\arabic{table}}
  \setcounter{table}{0}

  \input{sections/supplementary_table.tex}

  \subsection*{Processing the FMT data}

    \subsubsection*{Data download and pre-processing}
    The main dataset used in this study contained stool samples (healthy and autistic individuals) from a fecal microbiome transplant dataset~\cite{Kang2017}.
    The data containing the 16S sequencing reads (V4 region) was downloaded from Qiita~\cite{qiita} (study id: 10532).
    Only runs 2, 3, and 4 were used for the subsequent analysis because these runs were paired-end sequencing data whereas run 1 was single-end.
    The sample metadata was updated so as to contain only bmi, sex, height, weight and experimental group.
    This was necessary as some of the network inference algorithms (like \ac{mldm}) required information about envioronmental heterogeneity.
    However, these results were not included in the current analyses.

    \subsubsection*{Processing using the \ac{micone} pipeline}
    The data was then processed using the \ac{micone} pipeline starting at the \ac{sp} step and ending at the \ac{ni} step with the consensus algorithm.
    The configuration files (main.nf and nextflow.config) used to run the \ac{micone} pipeline as well the details of the pipeline execution (dag, report, timeline and trace) are in the "runs/FMT" directory of the data and scripts repository (\href{https://github.com/segrelab/MiCoNE-pipeline-paper}{https://github.com/segrelab/MiCoNE-pipeline-paper})
    % TODO: Store pipeline results
    The results of the pipeline execution are stored on Zenodo[REF] at ...

  \subsection*{Processing the mock data}

    \subsubsection*{Data download and pre-processing}
    The mock datasets, mock4, mock12 and mock16 used for this study, were obtained from mockrobiota~\cite{Bokulich2016}.
    Mock 4 is a mock community composed of 21 bacterial strains represented in equal abundances in two replicate samples, and the same strains represented in uneven abundances in two replicate samples.
    Mock 12 is composed of 27 bacterial strains containing closely related taxa, the members of which were chosen in part for their well-separated 16S rRNA gene sequences. Some pairs of strains differ by as little as one nucleotide, but all the strains are distinguishable over the sequenced region of the 16S rRNA gene.
    Mock 16 is a mock community composed of even amounts of purified genomic DNA from 49 bacteria and 10 archaea.
    The datasets did not require any preprocessing and could be directly used as input to the pipeline

    \subsubsection*{Processing using the \ac{micone} pipeline}
    The data was processed using the \ac{micone} pipeline starting at the \ac{sp} step and ending at the \ac{op} step with the filtered taxonomic tables as the final output.
    The configuration files (main.nf and nextflow.config) used to run the \ac{micone} pipeline as well the details of the pipeline execution (dag, report, timeline and trace) are in the "runs/mock*" directory of the data and scripts repository (\href{https://github.com/segrelab/MiCoNE-pipeline-paper}{https://github.com/segrelab/MiCoNE-pipeline-paper})
    % TODO: Store pipeline results
    The results of the pipeline execution are stored on Zenodo[REF] at ...

  \subsection*{Synthetic interaction data}

    \subsubsection*{Data generation}
    The synthetic interaction data for the study were generated using two methods.
    The first method, ``seqtime''~\cite{faustSignaturesEcologicalProcesses2018} utilized generalized Lotka-Volterra (gLV) equations to model the microbial community dynamics and made use of the Klemm–Eguı́luz algorithm to generate clique-based interaction networks~\cite{Rottjers2018}.
    We used the seqtime R package to simulate communities with different numbers of species and samples (see Methods for details).
    The second method, ``NorTA'' used the Normal to Anything (NorTA) approach coupled with a given interaction network topology to generate the abundance distribution of the microbial community~\cite{Kurtz2015}.
    We used the spieceasi R package to simulate communities with different abundance distributions and network topologies (see Methods for details).
    The scripts to generate these datasets can be found in the synthetic data and scripts repository (\href{https://github.com/segrelab/MiCoNE-synthetic-data}{https://github.com/segrelab/MiCoNE-synthetic-data})

    \subsubsection*{Processing using the \ac{micone} pipeline}
    The data was processed using the \ac{micone} pipeline using only the \ac{ni} step with the consensus networks as the final output.
    The configuration files (main.nf and nextflow.config) used to run the \ac{micone} pipeline as well the details of the pipeline execution (dag, report, timeline and trace) are in the "runs/norta" and "runs/seqtime" directories of the data and scripts repository (\href{https://github.com/segrelab/MiCoNE-pipeline-paper}{https://github.com/segrelab/MiCoNE-pipeline-paper})
    % TODO: Store pipeline results
    The results of the pipeline execution are stored on Zenodo[REF] at ...

  \subsection*{Effects of the \ac{dc} and \ac{op} steps on network variability}

    Figure~\ref{fig:figure_s1} describes the variation in the inferred networks in the first two principal axes and is similar to Figure~\ref{fig:figure2}B.
    The \ac{dc} step does not seem to have any correlation with the similarity of networks on the PCA plot, but all the networks with filtering at the \ac{op} step are similar to each other.
    This further confirms that the variability in the networks decreases upon filtering out the taxonomic entities at low abundance.

    \begin{figure}[H]
      \centering
      \includegraphics[width=1.0\linewidth]{figure_s1.pdf}
    \end{figure}
    \begin{figure}[H]
      \centering
        \caption{
          \textbf{The variation in the inferred networks in the first two principal axes}
          All combinations of inferred networks are shown as points on a PCA plot.
          Each point on the PCA plot represents a network inferred using different combinations of tools and parameters that are available in the \ac{micone} pipeline.
          The points are colored by the tools or parameters used in the \ac{dc} step (A) and the \ac{op} step (B).
        }
      \label{fig:figure_s1}
    \end{figure}
    \FloatBarrier
    \newpage

    % TODO: Verify this about t-SNE
    \begin{figure}[H]
      \centering
      \includegraphics[width=1.0\linewidth]{figure_s2.pdf}
    \end{figure}
    \begin{figure}[H]
      \centering
        \caption{
          \textbf{The t-SNE plot of the networks inferred by various methods}.
          The points are colored by the tools and parameters used in \ac{dc} step (A), \ac{ta} step (B), \ac{op} step (C) and \ac{ni} step (D).
          The separation of the points based on taxonomy reference database shows that the points might cluster based on reference database in high-dimensional space.
        }
      \label{fig:figure_s2}
    \end{figure}
    \FloatBarrier
    \newpage

  \subsection*{Similarity of high abundance reference sequences}

    Figure~\ref{fig:figure_s3} is similar to Figure~\ref{fig:figure3} shows the average UniFrac distance between reference sequences generated by the various methods in the \ac{dc} step.
    In Figure~\ref{fig:figure_s3} however, we use only the top 1000 representative sequences (by abundance) for this calculation.
    We observe that both the weighted and unweighted UniFrac distances are increased compared to the figure with the all the representative sequences.
    This shows that the 1000 most abundant representative sequences generated by the methods are not similar to each other.
    And since the weighted UniFrac is much smaller than the unweighted UniFrac distance, we can conclude that those reference sequences that are present in the middle of the abundance distribution are dissimilar.

    \begin{figure}[H]
      \centering
      \includegraphics[width=1.0\linewidth]{figure_s3.pdf}
    \end{figure}
    \begin{figure}[H]
      \centering
        \caption{
          \textbf{The UniFrac distance between the 1000 most abundant representative sequences generated by various method in the \ac{dc} step}
        }
      \label{fig:figure_s3}
    \end{figure}
    \FloatBarrier
    \newpage

    We find that the two chimera checking methods, uchime and remove bimera, produce similar outputs.
    This can be verified by comparing the output (representative sequence distributions) of the two chimera checking methods for each denoising method (Figure~\ref{fig:figure_s4}).
    We find that with the exception of de novo and open-reference under the unweighted UniFrac metric, all the other methods have low dissimilarity.
    This is especially true for the \ac{dada2} and Deblur methods which are the recommended denoising methods in the \ac{micone} pipeline.
    Therefore, we recommended remove bimera as the default chimera method if one is using \ac{dada2} and uchime-denovo when one is using Deblur, since these methods were developed for these respective algorithms (\ac{qiime2} uses uchime-denovo in the Deblur workflow).

    \begin{figure}[H]
      \centering
      \includegraphics[width=1.0\linewidth]{figure_s4.pdf}
    \end{figure}
    \begin{figure}[H]
      \centering
        \caption{
          \textbf{The weighted and unweighted UniFrac distance between representative sequences generated using remove bimera and uchime for each denoising method.}
        }
      \label{fig:figure_s4}
    \end{figure}
    \FloatBarrier
    \newpage

  \subsection*{Mismatches in all assignments at the \ac{ta} step}

    Figure~\ref{fig:figure_s5} is similar to Figure~\ref{fig:figure4}B, but instead of the matching only the top 100 taxonomic entities (by abundance), we match all the assignments from one database with those from the other two databases.
    We observe that the percentage of mismatches are indeed higher when considering all the assignments, implying that matching of the taxonomies in the more abundant sequences are more consistent.

    \begin{figure}[H]
      \centering
      \includegraphics[width=1.0\linewidth]{figure_s5.pdf}
    \end{figure}
    \begin{figure}[H]
      \centering
        \caption{
          \textbf{The pairwise comparison of assignments generated using different databases for each representative sequence}
        }
      \label{fig:figure_s5}
    \end{figure}
    \FloatBarrier
    \newpage

  \subsection*{Network metrics}

  In Table~\ref{tab:network_metrics} we show various global network metrics calculated for each tool in the pipeline.
  All the networks that make use of a particular tool are grouped together and the average metrics are calculated for each group.
  All the metrics were calculated using the \texttt{networkx} Python package~\cite{hagbergExploringNetworkStructure2008}.
  \begin{enumerate}
    \item The average shortest path length describes the average of all the shortest paths in the graph. No number is reported if the graph is not connected, thereforce, none of the networks that make use of \ac{harmonies}, \ac{cozine}, \ac{spring}, \ac{spieceasi} and Pearson are connected.
    \item The average clustering is the average clustering coefficient of the graph. The closer the value is to 1.0, the more densely connected is the graph. We can observe that the networks that use correlation-based methods have the highest values while the direct-association based methods have the lowest.
    \item The number of connected components are the highest for the direct-association based methods and the lowest for the correlation-based methods. In the case of propr, all the networks have only one giant component.
    \item Modularity metric is the average modularity over all partitions in a graph calculated using a label propagation algorithm. Positive values imply that there are more edges between vertices of the same type than we would expect by chance, and negative means that there are less. The networks inferred by \ac{mldm} report very few edges, and skew the average modularity scores.
    \item Node connectivity refers to the minimum number of nodes that must be removed from the graph to make it disconnected. We observe that only the networks generated using propr have a high value since most of these networks are connected.
    \item Degree assortativity coefficient measures the similarity of connections in the graph with respect to the node degree. Again we observe that the direct-association based methods have negative degree assortativity, meaning that there are many hubs in these networks. The correlation-based methods have positive values implying that in these networks nodes with similar degrees attach to one another.
  \end{enumerate}

  \begin{landscape}
  \begin{table}[H]
    \centering
    \small
    \begin{tabular}{|l|p{1cm}|p{1cm}|p{1cm}|p{2cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
  \hline
  DC & CC            & TA                & OP          & NI         & Average shortest path length & Average clustering & No. of connected components & Modularity & Node connectivity & Degree assortativity coefficient \\ \hline
  DB & -             & -                 & -           & -          & 2.066                        & 0.265              & 27.088                      & 0.387      & 1.868             & 0.070                            \\
  OR & -             & -                 & -           & -          & 1.904                        & 0.273              & 24.868                      & -17.060    & 1.877             & 0.099                            \\
  D2 & -             & -                 & -           & -          & 2.263                        & 0.267              & 28.228                      & 0.326      & 1.789             & 0.078                            \\
  DN & -             & -                 & -           & -          & 2.065                        & 0.272              & 25.132                      & 0.302      & 1.754             & 0.093                            \\
  CR & -             & -                 & -           & -          & 1.937                        & 0.276              & 24.289                      & -1.865     & 2.079             & 0.097                            \\
  -  & remove bimera & -                 & -           & -          & 2.070                        & 0.272              & 25.968                      & -7.439     & 1.863             & 0.086                            \\
  -  & uchime        & -                 & -           & -          & 2.066                        & 0.269              & 25.874                      & 0.275      & 1.884             & 0.089                            \\
  -  & -             & NCBI              & -           & -          & 2.218                        & 0.262              & 22.784                      & -3.683     & 1.495             & 0.100                            \\
  -  & -             & SILVA             & -           & -          & 1.872                        & 0.275              & 30.716                      & 0.415      & 2.674             & 0.074                            \\
  -  & -             & GG                & -           & -          & 2.086                        & 0.274              & 24.263                      & -7.478     & 1.453             & 0.088                            \\
  -  & -             & -                 & On          & -          & 1.975                        & 0.252              & 18.493                      & -7.194     & 1.880             & 0.073                            \\
  -  & -             & -                 & Off         & -          & 2.193                        & 0.291              & 34.174                      & 0.431      & 1.867             & 0.104                            \\
  -  & -             & -                 & -           & propr      & 1.650                        & 0.528              & 1.000                       & 0.000      & 10.583            & 0.036                            \\
  -  & -             & -                 & -           & harmonies  &                              & 0.108              & 82.633                      & 0.757      & 0.000             & 0.340                            \\
  -  & -             & -                 & -           & flashweave & 3.878                        & 0.079              & 1.800                       & 0.458      & 0.383             & -0.032                           \\
  -  & -             & -                 & -           & cozine     &                              & 0.090              & 82.167                      & 0.694      & 0.000             & -0.072                           \\
  -  & -             & -                 & -           & spring     &                              & 0.092              & 11.767                      & 0.566      & 0.000             & -0.035                           \\
  -  & -             & -                 & -           & sparcc     & 1.747                        & 0.525              & 1.033                       & 0.009      & 5.500             & -0.011                           \\
  -  & -             & -                 & -           & spieceasi  &                              & 0.076              & 39.383                      & 0.717      & 0.000             & -0.031                           \\
  -  & -             & -                 & -           & pearson    &                              & 0.457              & 23.883                      & 0.551      & 0.000             & 0.478                            \\
  -  & -             & -                 & -           & spearman   & 1.875                        & 0.551              & 1.450                       & 0.044      & 1.117             & 0.170                            \\
  -  & -             & -                 & -           & mldm       & 2.760                        & 0.130              & 2.267                       & -75.648    & 0.433             & -0.028                           \\ \hline
  \end{tabular}
  \caption{
    \textbf{Table of global network metrics for all combinations of networks.}
    The metrics are averaged for each tool in every step of the pipeline, implying that all combinations of networks that use a particular tool are grouped and averaged and their metrics are reported.
  }
  \label{tab:network_metrics}
  \end{table}
  \end{landscape}


  \subsection*{p-value merging}

  Fisher~\cite{fisher_224a_1948} proposed that for $w$ independent p-values, each generated by $w$ different methods and denoted by $\bar{P}^i$, the following will hold true for the statistic $\Psi$:
  \begin{equation*}
    \begin{aligned}
      \Psi &= \sum_{i=1}^w -2 \log \left( \bar{P}^i \right) \\
        \Psi &\sim \chi^2_{2w}
    \end{aligned}
  \end{equation*}

  Brown~\cite{brown_400_1975} extended Fisher's method to dependent p-values by using a re-scaled $\chi^2$ distribution:
  \begin{equation*}
    \Psi \sim c \chi^2_{2f}
  \end{equation*}
  where, $f$ is the degrees of freedom and $c$ is the scale factor and are given by:
  \begin{equation*}
    f = \frac{\mathrm{E}[\Psi]^2}{\mathrm{Var}[\Psi]} ~~~\text{and}~~~ c = \frac{\mathrm{Var}[\Psi]}{2\mathrm{E}[\Psi]} = \frac{w}{f}
  \end{equation*}

  Furthermore, Brown showed that $\mathrm{E}[\Psi]$ and $\mathrm{Var}[\Psi]$ can be calculated via a numerical integration:
  \begin{equation*}
    \mathrm{E}[\Psi] = 2w ~~~\text{and}~~~ \mathrm{Var}[\Psi] = 4w + 2\sum_{i<j} \mathrm{Cov}\left( -2\log(\bar{P}^i), -2\log(\bar{P}^j) \right)
  \end{equation*}

  Kost and McDermott~\cite{kost_combining_2002} further fit a third-order polynomial to approximate the covariance
  \begin{equation}
    \mathrm{Cov}\left( -2\log(\bar{P}^i), -2\log(\bar{P}^j) \right) \approx 3.263 \rho_{ij} + 0.710 \rho_{ij}^2 + 0.027 \rho_{ij}^3
    \label{eqn:covariance-pvalues}
  \end{equation}
  where, $\rho_{ij}$ is the correlation between method $i$ and method $j$

  The final combined p-value~\cite{Poole_Gibbs_Shmulevich_Bernard_Knijnenburg_2016} is then given by:
  \begin{equation}
    \begin{aligned}
        & \hat{P}_j = 1.0 - \Phi_{2f}\left( \psi / c \right) \\
        \text{where},~ &\psi = -2 \sum_{i=1}^w \log(\bar{P}^i_j) ~~~\text{and}~~~ \Phi_{2f} = \mathrm{CDF}\left( \chi^2_{2f} \right)
    \end{aligned}
    \label{eqn:pvalue-combined}
  \end{equation}

  The p-value merging and consensus method in \ac{micone} (refer Documentation) uses Equation~\ref{eqn:covariance-pvalues} to estimate the covariance of the pvalues and Equation~\ref{eqn:pvalue-combined} to merge the p-values (obtained from bootstrapping) from the different correlation methods.
  Note that we do not use Pearson and Spearman methods in the p-value merging step and these algorithms are only used for demonstration and comparison.
  The combined p-values are used to threshold for significance during the consensus network step.

  \subsection*{Performance of alternate consensus network on NorTA data}

    In Figure~\ref{fig:figure_s6} we calculate the consensus network by also taking into account the networks inferred by the Pearson and Spearman methods.
    We see that the consensus networks in this case do not perform as well as those networks that did not incorporate these two algorithms.
    However, we still observe that the consensus network at some parameter values still outperforms the best network inference method (\ac{spieceasi}).

    % TODO: Rerun this figure
    \begin{figure}[H]
      \centering
      \includegraphics[width=1.0\linewidth]{figure_s6.pdf}
    \end{figure}
    \begin{figure}[H]
      \centering
        \caption{
          \textbf{The precision and sensitivity of the inferred networks on the NorTA synthetic interaction data with Pearson and Spearman added to the consensus.}
            The ``I'' prefix indicates the individual network inference methods and the ``X'' prefix denotes the different consensus based methods.
            The different consensus based methods used are: pvalue merging (PM), scaled-sum (SS) and simple voting (SV) method.
            With the addition of Pearson and Spearman in the consensus calculation we observe a decrease in the average precision scores of both the consensus algorithms.
            The overall best precision was still consistently obtained by the scaled-sum method (0.985, 0.963 and 1.000), but the performance was not stable to changes in parameter value.
            The simple voting method when using presence of edges in all inferred networks as a requirement (parameter value 1.000), again outperforms \ac{spieceasi} on average precision (0.961).
        }
      \label{fig:figure_s6}
    \end{figure}
    \FloatBarrier
    \newpage


  \subsection*{Performance of network inference algorithms on seqtime data}

    In Figure~\ref{fig:figure_s7} we perform the same analysis we did with the NorTA data using the seqtime data.
    We observe that the best performing network inference algorithm is \ac{spieceasi}, but the consensus algorithms, both the scaled-sum and simple voting methods outperform it in terms of precision.
    These results show that the scaled-sum method is much better suited for inferring robust and accurate interactions from count data regardless of the distributions, topologies and number of samples in the data.

    \begin{figure}[H]
      \centering
      \includegraphics[width=1.0\linewidth]{figure_s7.pdf}
    \end{figure}
    \begin{figure}[H]
      \centering
        \caption{
          \textbf{The precision and sensitivity of the inferred networks on the seqtime synthetic interaction data.}
          The ``I'' prefix indicates the individual network inference methods and the ``X'' prefix denotes the different consensus based methods.
          The different consensus based methods used are: pvalue merging (PM), scaled-sum (SS) and simple voting (SV) method.
          Pearson and Spearman methods are not used in the calculation of the consensus.
          Among all the independent network inference methods, \ac{spieceasi} has the best average precision (0.624), but the overall best precision was consistently obtained by the scaled-sum method (0.688, 0.820 and 1.000).
          The simple voting method when using presence of edges in all inferred networks as a requirement (parameter value 1.000), also outperforms \ac{spieceasi} on average precision (0.692).
        }
      \label{fig:figure_s7}
    \end{figure}
    \FloatBarrier
    \newpage


  % TODO: Should we mention the MIND database here?
  \subsection*{The JSON network format and network exports}

    The default format \ac{micone} uses for storing the network files is the JSON (JavaScript Object Notation) format.
    The custom JSON schema we have designed is able to store all network related information from nodes and links to metadata related to links and datasets.
    Additionally, \ac{micone} also supports exporting of networks into a variety of other formats such as edge lists, .gml and cytoscape formats.
    Since, we make use of \texttt{networkx}~\cite{hagbergExploringNetworkStructure2008} for the export functionality, networks can be exported to all supported formats but the corresponding metadata might not be exported appropriately.
    The details of the format and information about importing/exporting it and other network formats can be found in the \ac{micone} documentation.
