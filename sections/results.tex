%!TEX root = ../main.tex

\section*{Results}

We introduce (\hl{insert name here}) a flexible and modular pipeline for 16S data analysis. It incorporates various popular, publicly available tools as well as custom

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{mind_pipeline.pdf}
    \caption{
      \textbf{The workflow of the microbial co-occurrence analysis pipeline}.
      The processes can be grouped into four major steps: \textbf{(A)} denoising and clustering, \textbf{(B)} taxonomy assignment, \textbf{(C)} \ac{otu}/\ac{esv} processing, and \textbf{(D)} network inference.
      Each step incorporates several processes, each of which in turn have several alternate algorithms for the same task (indicated by the text to the right of the blue boxes).
    }
    \label{fig:mind_pipeline}
  \end{figure}

  \FloatBarrier

  \subsection*{Variance among co-occurrence networks}

  Figure \ref{fig:variance} shows the fraction of total variation in the networks as contributed by four different steps in the pipeline.
  \todo[size=\footnotesize]{Results being processed}

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{main_figure.png}
    \caption{\textbf{Percentage of variance in the final co-occurrence network due to each processing step.}}
    \label{fig:variance}
  \end{figure}


  \FloatBarrier

  \subsection*{Denoising and clustering methods are very dissimilar}

  There is significant variation both in the networks as well as the \ac{otu}/\ac{esv} tables when different combinations of methods are used to generate them.
  The \ac{esv} tables generated by methods that perform denoising are very similar to each other and the \ac{otu} tables generated by the clustering methods are very similar to each other, but results of denoising and clustering are highly uncorrelated as shown in Figure \ref{fig:otu_correlations}
  The common core network (network made up of edges that are predicted by all methods) is very small compared to the total number of edges predicted by all the methods (Figure \ref{fig:denoise_network}).
  In this result, only the denoising method was changed (database used: \ac{gg} and network inference: \ac{sparcc}).

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{otu_corr_full.pdf}
    \caption{
      \textbf{Comparison of various denoising and clustering algorithms used in the pipeline}.
      (A, B) Correlation of the abundances of the taxa that are common between the count matrices created by two different methods.
      (A) The best correlation (most similar methods) is between open-reference and denovo.
      (B) The worst correlation (least similar methods) is between open-reference and dada2.
      (C) A heatmap showing the $\mathrm{R}^2$ of all pairwise comparisons of the methods.
    }
    \label{fig:otu_correlations}
  \end{figure}

  \FloatBarrier

  \subsection*{Taxonomy databases vary widely in taxonomy hierarchy and update frequency}

  SILVA and \ac{gg} are two popular 16S databases used for taxonomy identification.
  The two databases vastly differ in terms of their last update status - \ac{gg} was last updated on May 2013 and SILVA was last updated on December 2017.
  Since updates to taxonomic classifications are frequent, these two databases vary significantly \cite{Balvociute2017}.
  As a consequence of this, when different taxonomy databases are used on the same data-set we see large numbers of misclassifications \ref{fig:tax_mismatches}.

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{tax_comp_full.pdf}
    \caption{\textbf{Taxonomy composition of the 20 most abundant genera predicted using different taxonomy references databases}. NOTE: I will replace the legend with the taxonomy tree}
    \label{fig:tax_comparison}
  \end{figure}

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{tax_distance_deblur.pdf}
    \caption{\textbf{Average percentage of mismatches in taxonomy assignment at various taxonomy levels}. NOTE: I will include a boxplot of the weighted distance in the taxonomy tree}
    \label{fig:tax_mismatches}
  \end{figure}

  \subsection*{Network inference contributes to the most variance}

  Different network inference methods infer significantly different association networks.
  We can divide the network inference methods into two sets, the first set of methods (Pearson, Spearman, \ac{sparcc}) infer pairwise correlations while the second set infer direct associations (\ac{spieceasi}, \ac{mldm}, \ac{daa}).
  Our preliminary analysis (Figure \ref{fig:network_comparison}) shows that networks generated using 4 different methods (Pearson, Spearman, \ac{sparcc}, \ac{spieceasi}) are vastly different and the degree of similarity (number of edges that overlapped) between the methods was dependent on the data-set used.
  The abundance profiles of the different data-sets used are show in Figure \ref{fig:abundance_profile}.

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{net_inference_comparison.pdf}
    \caption{
      \textbf{Networks generated using different network inference methods}.
      The four different networks generated by different network inference methods are very dissimilar (C).
      (A) The overlaps between the edges among the network5 generated is shown. The number of edges that are common to all networks are very low (5).
      (B) The hamming distance between the networks is shown. The similarity between various methods was found to vary with the data-source used.
    }
    \label{fig:network_comparison}
  \end{figure}

  \begin{figure}[h]
    \centering
    %\includegraphics[width=17.8cm]{../figures/network_comparison.pdf}
    \caption{\textbf{Core network captures known interactions in vaginal microbiota.} \textbf{(A)} Core network, obtained by taking the intersection between all the different pipelines. \textbf{(B)} Vaginal microbiota network as determined by XXX.}
    \label{fig:real_network}
  \end{figure}

  % TODO: Based on these results: What is the best pipeline we recommend?
  The pipeline and the data visualization tool help the user explore the effect of the various methods on their data.
  Exploring these differences are difficult and inconvenient without the tool since different tools differ in their input and output formats and require inter-converting between the various formats.
  In the case of our pipeline, this is handled automatically.
