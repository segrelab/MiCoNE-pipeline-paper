%!TEX root = ../main.tex

\section*{Materials and Methods}

  \subsection*{16S rRNA sequencing Datasets}

  \vspace{-5mm}
    The study uses two kinds of 16S rRNA sequencing datasets: biological datasets and mock datasets.
    Biological datasets are collections of sequencing reads obtained from naturally occurring microbial community samples.
    The current analysis used stool samples from a fecal microbiome transplant study of autism~\cite{Kang2017} as biological datasets.
    The study was composed of multiple sequencing runs and those runs that contained paired end reads (runs 2, 3 and 4), were downloaded from Qiita~\cite{qiita} from https://qiita.ucsd.edu/study/description/10532 and used as input sequences for the \ac{micone} pipeline.
    % TODO: How many samples are there for each and average number of reads.
    Sequences from both control (x samples containing xx reads) and autistic (y samples containing yy reads) patients were included in the analyses but the groups were analyzed independently in the pipeline.
    The mock community 16S datasets are sequencing data obtained for artificially assembled collections of species in known proportions.
    The mock datasets used for this study, obtained from mockrobiota~\cite{Bokulich2016}, are labelled mock4, mock12 and mock16.
    The mock4 community is composed of 21 bacterial strains.
    Two replicate samples from mock4 contain all species in equal abundances, and two additional replicate samples contain the same species in unequal abundances.
    The mock12 community is composed of 27 bacterial strains that include closely related taxa with some pairs having only one to two nucleotide difference from another.
    The mock16 community is composed of 49 bacteria and 10 archea, all represented in equal amount.

  \subsection*{\ac{micone}}

  \vspace{-5mm}
  The flowchart describing the workflow of \ac{micone} (\acl{micone}), our complete 16S data-analysis pipeline, is shown in Figure \ref{fig:figure1}.
  The pipeline integrates many publicly available tools as well as custom R or Python modules and scripts to extract co-occurrence associations from 16S sequence data.
  Each of these tools corresponds to a distinct R or python module that recapitulates the relevant analyses.
  All such individual modules are available as part of the \ac{micone} package.
  The inputs to the pipeline by default are raw untrimmed 16S rRNA sequence reads, but the software can be alternatively configured to use trimmed sequences, \ac{otu} tables and other types of intermediate data.
  The pipeline supports both paired end and single end reads, and additionally supports independently processing multiple runs and merging the OTU tables in the DC step.
  The final output of the pipeline is the inferred network of co-occurrence relationships among the microbes present in the samples.

  The \ac{micone} pipeline provides both a Python API as well as a command-line interface and only uses a single configuration file (nextflow.config) to contain the configuration parameters.
  The configuration file along with the run file (main.nf) lists the inputs, output and the steps to be performed during runtime, along with the parameters to be used (if different from defaults) for the various steps.
  Since the entire pipeline run-through is stored in the form of a text file (the configuration file), subsequent runs are highly reproducible and changes can be easily tracked using version control.
  It uses the nextflow workflow manager~\cite{Tommaso2015} under the hood, making it readily usable on local machines, cluster or cloud with minimal configuration change.
  It also allows for automatic parallelization of all possible processes, both within and across samples.
  The pipeline is designed to be modular: each tool or method is organized into modules which can be easily modified or replaced.
  This modular architecture simplifies the process of adding new tools (refer to modules section in the \ac{micone} documentation).
  % In addition to the Python package, the entire pipeline has been containerized into a Docker~\cite{Merkel1994} image (\hl{dockerhub link}) for easy deployment and setup.
  The main components of the pipeline are detailed in the subsequent sections.

  \subsection*{Sequence Processing (SP)}
  This module deals with processing the raw multiplexed 16S sequence data into demultiplexed, quality-controlled, trimmed sequences.
  It consists of the following processes: demultiplexing and trimming (includes quality control and filtering).
  The trimming process handles the quality control steps such as trimming adapters and trimming low-quality nucleotide stretches from the sequences.
  The parameters and tools in this process are fixed and are not available for user customization.
  The various tools used for the processes were adapted from \ac{qiime2} v2021.8.0~\cite{bolyenReproducibleInteractiveScalable2019}.

  \subsection*{Denoising and Clustering (DC)}
  \vspace{-5mm}
  This module deals with processing the quality-controlled, trimmed 16S sequence data into \ac{otu} or \ac{esv} count tables.
  It consists of the following processes: denoising (or clustering) and chimera checking.
  The denoise/cluster process handles the conversion of the demultiplexed, trimmed sequences into \ac{otu} or \ac{esv} count tables (some methods, like closed reference and open reference clustering, perform clustering and taxonomy assignment in the same step).
  The chimera checking process handles the removal of chimeric sequences created during the \ac{pcr} step.
  The output of this module is a matrix of counts, that describes the number of reads of a particular \ac{otu} or \ac{esv} (rows of the matrix) present in each sample (columns of the matrix).
  The options currently available in the pipeline for denoising and clustering are: open reference clustering, closed reference clustering and de novo clustering methods from the vsearch plugin of \ac{qiime2} v2021.8.0~\cite{bolyenReproducibleInteractiveScalable2019} and denoising methods from \ac{dada2} v1.14~\cite{Callahan2016} and Deblur v1.1.0~\cite{Amir2017} (from the deblur plugin of \ac{qiime2}).
  The quality filtering and chimera checking tools are derived from those used in \ac{qiime2} v2021.8.0 (uchime method) and \ac{dada2} (remove bimera method).

  \begin{table}[h]
    \centering
    \small
    \begin{tabular}{|c|c|c|}
      \hline
      \textbf{Module} & \textbf{Tool} & \textbf{References} \\
      \hline
      Denoising and Clustering & Closed reference & \cite{rognesVSEARCHVersatileOpen2016,bolyenReproducibleInteractiveScalable2019} \\
      Denoising and Clustering & Open reference & \cite{rognesVSEARCHVersatileOpen2016,bolyenReproducibleInteractiveScalable2019} \\
      Denoising and Clustering & De novo & \cite{rognesVSEARCHVersatileOpen2016,bolyenReproducibleInteractiveScalable2019} \\
      Denoising and Clustering & Dada2 & \cite{Callahan2016} \\
      Denoising and Clustering & Deblur & \cite{Amir2017,bolyenReproducibleInteractiveScalable2019} \\
      \hline
      Chimera checking & Uchime & \cite{rognesVSEARCHVersatileOpen2016,bolyenReproducibleInteractiveScalable2019} \\
      Chimera checking & Remove bimera & \cite{Callahan2016} \\
    \end{tabular}
    \caption{Tools used in the DC module}
    \label{tab:dc_tools}
  \end{table}

  \subsection*{Taxonomy Assignment (TA)}
  \vspace{-5mm}
  This module deals with assigning taxonomies to either the representative sequences of the \ac{otu}s or directly to the \ac{esv}s.
  In order to assign taxonomies to a particular sequence we need a taxonomy database and a query tool.
  The taxonomy database contains the collection of 16S sequences of micro-organisms of interest and the query tool allows one to compare a sequence of interest to all the sequences in the database to identify the best matches.
  Finally, a consensus method is used to identify the most probable match from the list of best matches.
  The pipeline incorporates \ac{gg} 13\_8~\cite{DeSantis2006}, SILVA 138~\cite{Quast2012} and the \ac{ncbi} (16S RefSeq as of Oct 2021)~\cite{Sayers2009} databases for taxonomy assignment.
  These databases were downloaded and built using the RESCRIPt qiime2 plugin~\cite{iiRESCRIPtReproducibleSequence2021}.
  The Naive Bayes classifier from \ac{qiime2} and \ac{ncbi} blast as the query tools (from \ac{qiime2}).
  The consensus algorithm used is the default method used by the classifiers in \ac{qiime2}.

  \begin{table}[h]
    \centering
    \small
    \begin{tabular}{|c|c|c|}
      \hline
      \textbf{Module} & \textbf{Tool/Database} & \textbf{References} \\
      \hline
      Query tool & Blast & \cite{camachoBLASTArchitectureApplications2009} \\
      Query tool & Naive bayes classifier & \cite{bokulichOptimizingTaxonomicClassification2018} \\
      \hline
      Database & Greengenes & \cite{DeSantis2006} \\
      Database & SILVA & \cite{Quast2012} \\
      Database & NCBI RefSeq & \cite{Sayers2009} \\
    \end{tabular}
    \caption{Tools used in the TA module}
    \label{tab:ta_tools}
  \end{table}

  % TODO: Add references and basic equations or details
  \subsection*{OTU and ESV Processing (OP)}
  \vspace{-5mm}
  This module deals with normalization, filtering and applying transformations to the \ac{otu} or \ac{esv} counts matrix.
  The module also supports rarefaction, which is a normalization technique used to overcome the bias that might arise due to variable sampling depth in different samples.
  This is performed either by sub-sampling or by normalization of the matrix to the lowest sampling depth~\cite{Weiss2015}.
  Although the pipeline supports rarefaction, the analyses reported in the paper do not rareify the counts matrices.
  Filtering, is performed to remove samples or features (\ac{otu}s or \ac{esv}s) from the count matrix that are sparse.
  In order to determine the filtering threshold we fix the number of samples and correlation detection power needed and determine the number of features to be used.
  Finally, transformations are performed in order to correct for and overcome the compositional bias that is inherent in a counts matrix (in most cases this is handled by the network inference algorithm).

  \subsection*{Network Inference (NI)}
  \vspace{-5mm}
  This module deals with the inference of co-occurrence associations from the \ac{otu} or \ac{esv} counts matrix.
  The counts matrices are collapsed to the Genus level (or the required taxonomy level) by adding up the counts of \ac{otu} or \ac{esv} that map to the same taxa.
  These collapsed matrices are as used as input to the network inferrence methods to produce association matrices at the appropriate taxonomy level.
  These associations can be represented as a network, with nodes representing taxonomies of the micro-organisms and edges representing the associations between them.
  A null model is created by re-sampling and bootstrapping the correlation/interaction matrix and is used to calculate the significance of the inferred associations by calculating the p-values against this null model~\cite{Watts2018}.
  The pipeline includes Pearson, Spearman and FastSpar v0.0.10 (a faster implementation of \ac{sparcc})~\cite{Watts2018} as the pairwise correlation metrics, and \ac{spieceasi} v1.0.7~\cite{Kurtz2015}, \ac{mldm} v1.1~\cite{Yang2017} and \ac{magma}~\cite{Cougoul2019} as the direct association metrics.
  The Brown's p-value merging method~\cite{brown_400_1975} is used for combining p-values from the various methods to obtain a consensus p-value, which is used to create the consensus network.

  \subsection*{Consensus Network and p-value merging}
  \vspace{-5mm}

  \subsubsection*{Bootstrapping}
  For each network inference method (both correlation and direct association based methods), $1000$ permutations of the original \ac{otu} counts data were generated~\cite{Watts2018}.
  We then recalculate the associations in these permuted \ac{otu} tables using the different network inference algorithms.
  Finally, we calculate the p-value based on how often a more extreme association is observed for randomly permuted data.

  \subsubsection*{p-value merging (can be moved to the supplementary section)}
  Fisher~\cite{fisher_224a_1948} proposed that for $k$ independent p-values, each generated by $k$ different methods and denoted by $P_i$, the statistic $\Psi$:
  \begin{equation*}
    \begin{aligned}
        \Psi &= \sum_{i=1}^k -2 \log \left( P_i \right) \\
        \Psi &\sim \chi^2_{2k}
    \end{aligned}
  \end{equation*}

  Brown~\cite{brown_400_1975} extended Fisher's method to dependent p-values by using a re-scaled $\chi^2$ distribution:
  \begin{equation*}
    \Psi \sim c \chi^2_{2f}
  \end{equation*}
  where, $f$ is the degrees of freedom and $c$ is the scale factor and are given by:
  \begin{equation*}
    f = \frac{\mathrm{E}[\Psi]^2}{\mathrm{Var}[\Psi]} ~~~\text{and}~~~ c = \frac{\mathrm{Var}[\Psi]}{2\mathrm{E}[\Psi]} = \frac{k}{f}
  \end{equation*}

  Furthermore, Brown showed that $\mathrm{E}[\Psi]$ and $\mathrm{Var}[\Psi]$ can be calculated directly via a numerical integration:
  \begin{equation*}
    \mathrm{E}[\Psi] = 2k ~~~\text{and}~~~ \mathrm{Var}[\Psi] = 4k + 2\sum_{i<j} \mathrm{Cov}\left( -2\log(P_i), -2\log(P_j) \right)
  \end{equation*}

  Kost and McDermott~\cite{kost_combining_2002} further fit a third-order polynomial to approximate the covariance
  \begin{equation}
    \mathrm{Cov}\left( -2\log(P_i), -2\log(P_j) \right) \approx 3.263 \rho_{ij} + 0.710 \rho_{ij}^2 + 0.027 \rho_{ij}^3
    \label{eqn:covariance-pvalues}
  \end{equation}
  where, $\rho_{ij}$ is the correlation between method $i$ and method $j$

  The final combined p-value~\cite{Poole_Gibbs_Shmulevich_Bernard_Knijnenburg_2016} is then given by:
  \begin{equation}
    \begin{aligned}
        & P_{combined} = 1.0 - \Phi_{2f}\left( \psi / c \right) \\
        \text{where},~ &\psi = -2 \sum_{i=1}^k \log(P_i) ~~~\text{and}~~~ \Phi_{2f} = \mathrm{CDF}\left( \chi^2_{2f} \right)
    \end{aligned}
    \label{eqn:pvalue-combined}
  \end{equation}

  The consensus method in \ac{micone} (refer Documentation) uses Equation~\ref{eqn:covariance-pvalues} to estimate the covariance of the pvalues and Equation~\ref{eqn:pvalue-combined} to merge the p-values (obtained from bootstrapping) from different methods.
  Note that we do not use Pearson and Spearman methods in the p-value merging step and these algorithms are only used for demonstration and comparison.
  The combined p-values are used to threshold for significance during the consensus network step.

 \subsection*{NOTATION}

  Note this section defines the notation for the network comparison component of our pipeline, which assumes that all networks to be compared have the same number of nodes

  q = number of nodes

  w = number of different networks from different approaches (previously x?)

  $N^i$ = network k (currently Ni)

  $N^i_{a,b}$ = edge (a,b) in network i

  It useful to define a "stretched" version of each adjacency matrix $N^i$ into a column vector, where all columns are stacked onto each other into an $q^2$ long vector:

  $\bar{N}^i_{j}$ , $j=1:q^2$

  \subsection*{Consensus method}
  \vspace{-5mm}

  The consensus algorithm was designed to increase the number of true positives reported at the end of the network inference step. For this purpose, we designed two simple algorithms that combine the edges reported by the different network inference tools for each pair of nodes using a consensus based on a parameter \(p\). The inputs to both the algorithms are the interaction networks (association matrices) generated by each method \(N_{i}\) and the threshold parameter (p). Here, the \(N_{i}\) each have the same set of nodes and only differ by the value of the association inferred between every pair.

  \subsection*{Algorithm 1: Simple voting}
 

  The simple voting method performs a voting-based consensus to determine whether an edge will exist between a given node-pair in the final consensus network. For each pair of nodes \((\text{node}_{i}, \text{node}_{j})\), we determine the number of network inference methods that report an edge between them  (\(\text{edges}(\text{node}_{i}, \text{node}_{j})\)). Each node-pair will have an edge in the final consensus network if the number of reported edges is more than a threshold (Equation \ref{eqn:simple-voting})

 For each edge (i,j), we count number $M_{i,j}$ of networks in which that edge exists, i.e.:
 
 \begin{equation}
 \begin{aligned}
 M_{i,j} &= | \left{ a \mid N^{a}_{i,j}>0 \right} | \\
 M_{i,j} &\geq \lfloor \theta * w \rfloor
 \end{aligned}
  \label{eqn:simple-voting}
  \end{equation}
  
  \begin{equation}
  \text{edges}(\text{node}_{i}, \text{node}_{j}) \geq \lfloor \theta * w \rfloor
  \label{eqn:simple-voting}
  \end{equation}
  
   \begin{equation}
   \sum_k N^k_{i,j} \geq \lfloor \theta * w \rfloor
  \label{eqn:simple-voting2}
  \end{equation}
 
  
  where, \(w\) is the number of network inference methods used in the consensus.


 where, \theta is the user-defined threshold....

  The simple voting method gives the union of the networks when \(p \in (0, \frac{1}{x})\) and will return the intersection when \(p \in ((x - 1), 1)\). In general, if \(p \in ((n - 1), \frac{n}{x})\), this algorithm will report an edge in the consensus network when at least \(n\) network inference methods report this edge.

  \subsubsection*{Algorithm 2: Scaled-sum method}

  This algorithm performs a consensus based on sum of all edges reported between a node-pair. First, the network generated by each network inference method is re-scaled so that (\max(\mid N_{i} \mid) = 1) (Equation \ref{eqn:scaled-sum-rescaling}).


\begin{equation}
  NS^{a}_{i,j} = \frac{N^{(a)}_{i,j}}{\max(\mid N_{i} \mid)}
  \label{eqn:scaled-sum-rescaling}
  \end{equation}
  
  
  \begin{equation}
  N^{scaled}_{i} = \frac{N_{i}}{\max(\mid N_{i} \mid)}
  \label{eqn:scaled-sum-rescaling}
  \end{equation}

  The re-scaling is performed because the associations reported by the direct association metrics are not necessarily correlations and are not directly comparable to the associations from the correlation-based methods due to their lower weights. This problem can also be alleviated by weighing each network inference method differently. Next, for each pair of nodes, we sum the weights of all reported edges (Equation \ref{eqn:scaled-sum}).

  \begin{equation}
  \text{scaled\_sum}(\text{node}_{m}, \text{node}_{n}) = \sum_{i} N^{scaled}_{i}(\text{node}_{m}, \text{node}_{n})
  \label{eqn:scaled-sum}
  \end{equation}

  An edge will exist between a given node-pair in the consensus network if \(\text{scaled\_sum} > (x - 1) * p\), where \(x\) is the number of network inference methods used in the consensus. The advantage of this method is that it also takes into account how the strength of the association reported for that particular node is in the inferred networks.

  \subsubsection*{Network Variability}
  \vspace{-5mm}
 In order to compare across different networks, and analyze the degree of variability induced by the choice of different modules and parameters, we organized multiple networks into a single mathematical structure that we could use for linear regression.
 In particular, we transformed the adjacency matrix of each co-occurrence network into a vector.
 We then merged the networks generated from all possible combinations of tools into a table (N, see below) in which each column represents one network.

 The merged table $N$ with $p$ edges and $n$ networks, where, each column $N_j$ is the vector representation of one of the networks, each row $L_i$ is the vector representation of one particular edge in all networks (assigned a value of 0 if the edge did not exist in the network but in other networks), and each element $E_{i,j}$ belongs to edge $L_i$ and network $N_j$.

  \begin{equation*}
   N_{p \times n} =
   \begin{bmatrix}
     L_1 \\
     L_2 \\
     \vdots \\
     L_p
   \end{bmatrix}
   =
   \begin{bmatrix}
     E_{1,1} & E_{1,2} & \cdots  & E_{1, n} \\
     E_{2,1} & E_{2,2} & \cdots  & E_{2, n} \\
     \vdots & \vdots & \vdots  & \vdots \\
     E_{p,1} & E_{p,2} & \cdots  & E_{p, n}
   \end{bmatrix}
  \end{equation*}

  In other words, $N$ is the merged table, each column $N_i$ is the vector representation of one of the networks, and each row $L_i$ represents one particular edge in all networks (assigned 0 if the edge does not exist in the network).

  We use linear regression to express each link $L_i$ as a linear function of categorical variables that describe the possible options in each of the first three steps of the pipeline.

  % TODO: Explain the categorical linear model and ANOVA better (text)
  In particular, we infer parameters $\alpha_i$ such that:
   \begin{equation*}
       L_i = \sum_{j=1}^5 \left( \alpha^{DC(j)}_i.\delta^{DC(j)}_i \right) +
             \sum_{j=1}^3 \left( \alpha^{TA(j)}_i.\delta^{TA(j)}_i \right) +
             \sum_{j=1}^2 \left( \alpha^{OP(j)}_i.\delta^{OP(j)}_i \right) +
             \epsilon_i
   \end{equation*}

   where, $\alpha_i$ are the coefficients of the regression, $\epsilon_i$ are the residuals and $\delta_i$ are the indicator variables that correspond to the processes utilized in the pipeline used to create the network $N_i$; for example, $\delta^{DC(1)}_i = 1$ if the DC(1) process was used in the generation of the network $N_i$ .
   Here, (i) DC(1) = "closed reference", DC(2) = "open reference", DC(3) = "de novo", DC(4) = "dada2", DC(5) = "deblur"; (ii)  TA(1) = "GreenGenes", TA(2) = "SILVA", TA(3) = "NCBI"; (iii) OP(1) = "no filtering", OP(2) = "filtering".

  The variance contributed by each step of the pipeline is calculated for every connection in the merged table through ANOVA using the Python statsmodels package and is shown in Figure~\ref{fig:figure2}A.
  The total variance for the network is calculated by adding the variances for each connection.
  The merged network table $N_{p \times n}$ is used as the input to the PCA analysis to generate Figure~\ref{fig:figure2}B.
  
  The possible correlations between the edges of the network lead to inaccurate estimates of the variance if a GLM were used to directly model the relationships between the links and steps in the workflow. Therefore, we transformed the network matrix $N$ using a Principal Component Analysis into the $N_{reduced}$ matrix. The dimensions of the $N_{reduced}$ matrix are be denoted by $(d \times n)$ where d is the number of principal components and n is the number of network in the $N$ matrix.



  \subsection*{Synthetic interaction data}
  \vspace{-5mm}

  We generated synthetic interaction data using two methodologies previously used for benchmarking network inference methods.

  The first method, hereby referred to as ``seqtime'', used generalized Lotka-Volterra (gLV) equations to model the microbial community dynamics and utilized the Klemm–Eguı́luz algorithm to generate a clique-based interaction network~\cite{rottjersHairballsHypothesesBiological2018}.
  We used the \href{https://github.com/hallucigenia-sparsa/seqtime}{seqtime} R package to simulate communities with number of species ($N$) varying from 10 to 150 (10, 25, 50, 100, 150 and 200).
  The initial species concentrations are randomly sampled from a Poisson distribution and the simulation is rerun to generate a number of samples ($S$) varying from 50 to 500 (50, 100, 200, 500) for different communities.
  The abundance values of the species in the community at the end of the simulation time are used to create the OTU table.

  The second method, hereby referred to as ``NorTA'', used the Normal to Anything (NorTA) approach coupled with a given interaction network topology to generate the abundance distribution of the microbial community \cite{kurtzSparseCompositionallyRobust2015}.
  We used the \href{https://github.com/zdk123/SpiecEasi}{spieceasi} R package to simulate communities with different network topologies (scale-free, cluster, block, Erdos-Renyi, band and hub) and target abundance distributions (Negative Binomial, Poisson, Zero-Inflated Negative Binomial).
  The OTU table was generated using the American Gut Project example in the \texttt{spieceasi} package (amgut1.filt) with the default parameter options.

  For each method, we generated the OTU table depicting the abundances of species and used this to generate association networks using \ac{micone}.
  The interaction matrix was used as the source of expected (true) interactions and the associations predicted using \ac{micone} were the source of predicted interactions.
  Finally, for each dataset we evaluated the precision and sensitivity of the associations predicted by the individual network inference methods as well as the consensus (Figure \ref{fig:figure7}).

  \subsection*{Code and Data Availability}
  Pipeline: \href{https://github.com/segrelab/MiCoNE}{https://github.com/segrelab/MiCoNE} \\
  Documentation: \href{https://micone.readthedocs.io}{https://micone.readthedocs.io} \\
  Data and scripts: \href{https://github.com/segrelab/MiCoNE-pipeline-paper}{https://github.com/segrelab/MiCoNE-pipeline-paper}
